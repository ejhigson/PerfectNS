{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# perfectns demo\n",
    "\n",
    "This notebook demonstrates the basic functionality of the `perfectns` module; for background see the README and the dynamic nested sampling paper [(Higson, 2017a)](https://arxiv.org/abs/1704.03459).\n",
    "\n",
    "### Running nested sampling calculations\n",
    "\n",
    "The likelihood $\\mathcal{L}(\\theta)$, prior $\\pi(\\theta)$ and calculation settings are specified in a PerfectNSSettings object. For this example we will use a 10-dimensional spherically symmetric Gaussian likelihood with size $\\sigma_\\mathcal{L}=1$ and a Gaussian prior with size $\\sigma_{\\pi}=10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import perfectns.settings\n",
    "import perfectns.likelihoods as likelihoods\n",
    "import perfectns.priors as priors\n",
    "\n",
    "# Input settings\n",
    "settings = perfectns.settings.PerfectNSSettings()\n",
    "settings.likelihood = likelihoods.Gaussian(likelihood_scale=1)\n",
    "settings.prior = priors.Gaussian(prior_scale=10)\n",
    "settings.n_dim = 10\n",
    "settings.nlive_const = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"dynamic_goal\" setting determines if dynamic nested sampling should be used and, if so, how to split the computational effort between increasing parameter estimation accuracy and evidence calculation accuracy. dynamic_goal=1 optimises purely for parameter estimation and dynamic_goal=0 optimises purely for calculating the Bayesian evidence $\\mathcal{Z}$.\n",
    "\n",
    "Lets try running standard nested sampling and dynamic nested sampling calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import perfectns.nested_sampling as nested_sampling\n",
    "\n",
    "# Perform standard nested sampling\n",
    "settings.dynamic_goal = None\n",
    "standard_ns_run = nested_sampling.generate_ns_run(settings, random_seed=0)  # set random_seed for reproducible results\n",
    "# Perform dynamic nested sampling\n",
    "settings.dynamic_goal = 1  # optimise for parameter estimation accuracy\n",
    "dynamic_ns_run = nested_sampling.generate_ns_run(settings, random_seed=0)  # set random_seed for reproducible results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now make posterior inferences using the samples generated by the nested sampling calculations. Here we calculate:\n",
    "\n",
    "1\\. the log Bayesian evidence $\\log \\mathcal{Z}=\\log \\left( \\int \\mathcal{L}(\\theta) \\pi(\\theta) \\mathrm{d}\\theta \\right)$,\n",
    "\n",
    "2\\. the mean of the first parameter $\\theta_1$,\n",
    "\n",
    "3\\. the second moment of the posterior distribution of $\\theta_1$,\n",
    "\n",
    "4\\. the median of $\\theta_1$,\n",
    "\n",
    "5\\. the 84% one-tailed credible interval on $\\theta_1$.\n",
    "\n",
    "For the Gaussian likelihood and prior we can calculate the posterior distribution analytically, so we first calculate the analytic values of each quantity for comparison. The results are displayed in a Pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import perfectns.estimators as e\n",
    "import nestcheck.ns_run_utils\n",
    "import pandas as pd\n",
    "\n",
    "estimator_list = [e.LogZ(),\n",
    "                  e.ParamMean(),\n",
    "                  e.ParamSquaredMean(),\n",
    "                  e.ParamCred(0.5),\n",
    "                  e.ParamCred(0.84)]\n",
    "estimator_names = [est.latex_name for est in estimator_list]\n",
    "results = pd.DataFrame([nestcheck.ns_run_utils.run_estimators(standard_ns_run, estimator_list),\n",
    "                        nestcheck.ns_run_utils.run_estimators(dynamic_ns_run, estimator_list)],\n",
    "                       columns=estimator_names, index=['standard run', 'dynamic run'])\n",
    "# Add true values for comparison\n",
    "results.loc['true values'] = e.get_true_estimator_values(estimator_list, settings)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating sampling errors\n",
    "\n",
    "You can estimate the numerical uncertainties on these results by calculating the standard deviation of the sampling errors distributions each run using the bootstrap resampling approach described in [Higson (2017b)](https://arxiv.org/abs/1703.09701)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nestcheck.error_analysis\n",
    "np.random.seed(0)\n",
    "results.loc['standard unc'] = nestcheck.error_analysis.run_std_bootstrap(\n",
    "    standard_ns_run, estimator_list, n_simulate=200)\n",
    "results.loc['dynamic unc'] = nestcheck.error_analysis.run_std_bootstrap(\n",
    "    dynamic_ns_run, estimator_list, n_simulate=200)\n",
    "results.loc[['standard unc', 'dynamic unc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating and analysing runs in parallel\n",
    "\n",
    "Multiple nested sampling runs can be generated and analysed in parallel (using the parallel utils from `nestcheck`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nestcheck.parallel_utils as pu\n",
    "import nestcheck.pandas_functions as pf\n",
    "\n",
    "# Generate 100 nested sampling runs\n",
    "run_list = nested_sampling.get_run_data(settings, 100, save=False, load=False, random_seeds=list(range(100)))\n",
    "# Calculate posterior inferences for each run\n",
    "values = pu.parallel_apply(nestcheck.ns_run_utils.run_estimators, run_list,\n",
    "                           func_args=(estimator_list,))\n",
    "# Show the mean and standard deviation of the calculation results\n",
    "multi_run_tests = pf.summary_df_from_list(values, estimator_names)\n",
    "multi_run_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing dynamic and standard nested sampling performance\n",
    "  \n",
    "Lets now compare the performance of dynamic and standard nested sampling, using the 10-dimensional Gaussian likelihood and prior. \n",
    "\n",
    "This is the code that was used for Table 1 of the dynamic nested sampling paper [(Higson, 2017a)](https://arxiv.org/abs/1704.03459), although we only use 100 runs instead of 5000. Tables 2, 3 and 4 can also be replicated by changing the settings; for more information about the get_dynamic_results function look at its docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import perfectns.results_tables as rt\n",
    "\n",
    "settings.likelihood = likelihoods.Gaussian(likelihood_scale=1)\n",
    "settings.prior = priors.Gaussian(prior_scale=10)\n",
    "settings.n_dim = 10\n",
    "dynamic_results_table = rt.get_dynamic_results(100, [0, 1], estimator_list, settings, save=False, load=False)\n",
    "dynamic_results_table[estimator_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that every second column gives an estimated numerical uncertainty on the values in the previous column.\n",
    "\n",
    "Looking at the final row of dynamic_results_table (above), you should see that dynamic nested sampling targeted at parameter estimation (dynamic goal=1) has an efficiency gain (equivalent computational speedup) for parameter estimation (columns other than $\\log \\mathcal{Z}$) of factor of around 3 to 4 compared to standard nested sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing bootstrap error estimates to observed distributions of results\n",
    "\n",
    "Finally lets check if the bootstrap estimates of parameter estimation sampling errors are accurate, using a 3d Gaussian likelihood and Gaussian prior.\n",
    "\n",
    "This is the code that was used for Table 5 of the dynamic nested sampling paper [(Higson, 2017a)](https://arxiv.org/abs/1704.03459), although we only use 100 runs instead of 5000. See the paper and the get_bootstrap_results function's docstring for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "settings.likelihood = likelihoods.Gaussian(likelihood_scale=1)\n",
    "settings.prior = priors.Gaussian(prior_scale=10)\n",
    "settings.n_dim = 3\n",
    "bootstrap_results_table = rt.get_bootstrap_results(50, 50, # 100, 200,\n",
    "                                                   estimator_list, settings,\n",
    "                                                   n_run_ci=20,\n",
    "                                                   n_simulate_ci=200,  # n_simulate_ci=1000,\n",
    "                                                   add_sim_method=False,\n",
    "                                                   cred_int=0.95,\n",
    "                                                   ninit_sep=True,\n",
    "                                                   parallel=True)\n",
    "bootstrap_results_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that every second column gives an estimated numerical uncertainty on the values in the previous column.\n",
    "\n",
    "You should see that the ratio of the bootstrap error estimates to bootstrap_results the standard deviation of results (row 4 of bootstrap_results_table) has values close to 1 given the estimated numerical uncertainties.'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
