{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# PerfectNS demo\n",
    "\n",
    "This notebook demonstrates the basic functionality of the PerfectNS module; for background see the README and the dynamic nested sampling paper [(Higson, 2017a)](https://arxiv.org/abs/1704.03459).\n",
    "\n",
    "### Running nested sampling calculations\n",
    "\n",
    "The likelihood $\\mathcal{L}(\\theta)$, prior $\\pi(\\theta)$ and calculation settings are specified in a PerfectNSSettings object. For this example we will use a 10-dimensional spherically symmetric Gaussian likelihood with size $\\sigma_\\mathcal{L}=1$ and a Gaussian prior with size $\\sigma_{\\pi}=10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import PerfectNS.settings\n",
    "import PerfectNS.likelihoods as likelihoods\n",
    "import PerfectNS.priors as priors\n",
    "\n",
    "# Input settings\n",
    "settings = PerfectNS.settings.PerfectNSSettings()\n",
    "settings.likelihood = likelihoods.gaussian(likelihood_scale=1)\n",
    "settings.prior = priors.gaussian(prior_scale=10)\n",
    "settings.n_dim = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The \"dynamic_goal\" setting determines if dynamic nested sampling should be used and, if so, how to split the computational effort between increasing parameter estimation accuracy and evidence calculation accuracy. dynamic_goal=1 optimises purely for parameter estimation and dynamic_goal=0 optimises purely for calculating the Bayesian evidence $\\mathcal{Z}$.\n",
    "\n",
    "Lets try running standard nested sampling and dynamic nested sampling calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import PerfectNS.nested_sampling as nested_sampling\n",
    "\n",
    "# Perform standard nested sampling\n",
    "settings.dynamic_goal = None\n",
    "standard_ns_run = nested_sampling.generate_ns_run(settings)\n",
    "# Perform dynamic nested sampling\n",
    "settings.dynamic_goal = 1  # optimise for parameter estimation accuracy\n",
    "dynamic_ns_run = nested_sampling.generate_ns_run(settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can now make posterior inferences using the samples generated by the nested sampling calculations. Here we calculate:\n",
    "\n",
    "1\\. the log Bayesian evidence $\\log \\mathcal{Z}=\\log \\left( \\int \\mathcal{L}(\\theta) \\pi(\\theta) \\mathrm{d}\\theta \\right)$,\n",
    "\n",
    "2\\. the mean of the first parameter $\\theta_1$,\n",
    "\n",
    "3\\. the second moment of the posterior distribution of $\\theta_1$,\n",
    "\n",
    "4\\. the median of $\\theta_1$,\n",
    "\n",
    "5\\. the 84% one-tailed credible interval on $\\theta_1$.\n",
    "\n",
    "For the Gaussian likelihood and prior we can calculate the posterior distribution analytically, so we first calculate the analytic values of each quantity for comparison. The results are displayed in a Pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import PerfectNS.estimators as e\n",
    "import PerfectNS.analyse_run as ar\n",
    "\n",
    "estimator_list = [e.LogZ(),\n",
    "                  e.ParamMean(),\n",
    "                  e.ParamSquaredMean(),\n",
    "                  e.ParamCred(0.5),\n",
    "                  e.ParamCred(0.84)]\n",
    "results = e.get_true_estimator_values(estimator_list, settings)\n",
    "results.loc['standard run'] = ar.run_estimators(standard_ns_run, estimator_list)\n",
    "results.loc['dynamic run'] = ar.run_estimators(dynamic_ns_run, estimator_list)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Estimating sampling errors\n",
    "\n",
    "You can estimate the numerical uncertainties on these results by calculating the standard deviation of the sampling errors distributions each run using the bootstrap resampling approach described in [Higson (2017b)](https://arxiv.org/abs/1703.09701)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "results.loc['standard unc'] = ar.run_std_bootstrap(standard_ns_run,\n",
    "                                                   estimator_list,\n",
    "                                                   n_simulate=200)\n",
    "results.loc['dynamic unc'] = ar.run_std_bootstrap(dynamic_ns_run,\n",
    "                                                  estimator_list,\n",
    "                                                  n_simulate=200)\n",
    "results.loc[['standard unc', 'dynamic unc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Generating and analysing runs in parallel\n",
    "\n",
    "Multiple nested sampling runs can be generated and analysed in parallel (this uses the concurrent.futures module)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import PerfectNS.parallelised_wrappers as pw\n",
    "import PerfectNS.maths_functions as mf\n",
    "\n",
    "# Generate 100 nested sampling runs\n",
    "run_list = pw.generate_runs(settings, 100, max_workers=4)\n",
    "# Calculate posterior inferences for each run\n",
    "values = pw.func_on_runs(ar.run_estimators, run_list, estimator_list,\n",
    "                           parallelise=True)\n",
    "# Show the mean and standard deviation of the calculation results\n",
    "estimator_names = [est.name for est in estimator_list]\n",
    "multi_run_tests = mf.get_df_row_summary(values, estimator_names)\n",
    "multi_run_tests.loc[['mean', 'std']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Comparing dynamic and standard nested sampling performance\n",
    "  \n",
    "Lets now compare the performance of dynamic and standard nested sampling, using the 10-dimensional Gaussian likelihood and prior. \n",
    "\n",
    "This is the code that was used for Table 1 of the dynamic nested sampling paper [(Higson, 2017a)](https://arxiv.org/abs/1704.03459), although we only use 100 runs instead of 5000. Tables 2, 3 and 4 can also be replicated by changing the settings; for more information about the get_dynamic_results function look at its docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import PerfectNS.results_tables as rt\n",
    "\n",
    "settings.likelihood = likelihoods.gaussian(likelihood_scale=1)\n",
    "settings.prior = priors.gaussian(prior_scale=10)\n",
    "settings.n_dim = 10\n",
    "dynamic_results_table = rt.get_dynamic_results(100, [0, 1], estimator_list, settings)\n",
    "dynamic_results_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Note that every second column gives an estimated numerical uncertainty on the values in the previous column.\n",
    "\n",
    "Looking at the final row of dynamic_results_table (above), you should see that dynamic nested sampling targeted at parameter estimation (dynamic goal=1) has an efficiency gain (equivalent computational speedup) for parameter estimation (columns other than $\\log \\mathcal{Z}$) of factor of around 3 to 4 compared to standard nested sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Comparing bootstrap error estimates to observed distributions of results\n",
    "\n",
    "Finally lets check if the bootstrap estimates of parameter estimation sampling errors are accurate, using a 3d Gaussian likelihood and Gaussian prior.\n",
    "\n",
    "This is the code that was used for Table 5 of the dynamic nested sampling paper [(Higson, 2017a)](https://arxiv.org/abs/1704.03459), although we only use 100 runs instead of 5000. See the paper and the get_bootstrap_results function's docstring for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "settings.likelihood = likelihoods.gaussian(likelihood_scale=1)\n",
    "settings.prior = priors.gaussian(prior_scale=10)\n",
    "settings.n_dim = 3\n",
    "bootstrap_results_table = rt.get_bootstrap_results(100, 200,\n",
    "                                                   estimator_list, settings,\n",
    "                                                   n_run_ci=20,\n",
    "                                                   n_simulate_ci=1000,\n",
    "                                                   add_sim_method=False,\n",
    "                                                   cred_int=0.95,\n",
    "                                                   ninit_sep=False,\n",
    "                                                   parallelise=True)\n",
    "bootstrap_results_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Note that every second column gives an estimated numerical uncertainty on the values in the previous column.\n",
    "\n",
    "You should see that the ratio of the bootstrap error estimates to bootstrap_results the standard deviation of results (row 4 of bootstrap_results_table) has values close to 1 given the estimated numerical uncertainties.'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
